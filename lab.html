<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aleira N. Sanchez - Labs</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Navigation Bar -->
    <nav>
        <a href="index.html" class="logo">Aleira N. Sanchez</a>
        <ul>
            <li><a href="index.html">Go back</a></li> <!-- Link back to the main page -->
        </ul>
    </nav>

    
    <!-- Labs Details Section -->
    <section id="labs-subpage">
        <div class="gallery">
            <section id="lab1a">
                <div class="lab-text">
                    <h1>Lab 1A: Artemis</h1>
                    <h3>Objective: <span class="objective-text">To familiarize myself with the Arduino IDE and the Artemis board. Get comfortable programming the board, managing basic outputs, communicating via serial connection, and utilizing the onboard sensors.</span></h3>
                    <h3>Pre-Lab: <span class="objective-text">Installed the latest versions of Arduino IDE and Sparkfun Apollo3 boards manager.</span></h3>
                    <h3>Task 1: Blink</h3>
                    <div class="video-container">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/ht9bpHsNnP4?si=W0C8Ul9ZaN7YtuvT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </div>
                    <p>Uploaded the Blink.ino code to the RedBoard Artemis Nano.</p>
                    <br> <!-- Line break -->

                    
                    <h3>Task 2: Serial</h3>
                    <div class="video-container">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/IysLmSLOE5M?si=1iehgUwczvUTOcoN" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </div>
                    <p>Uploaded the Example04_Serial.ino code to the RedBoard Artemis Nano.</p>
                    <br>

                    <h3>Task 3: Temperature</h3>
                    <div class="video-container">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/L2gW-0fc3KY?si=kfwtEcmecsuXr9p7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </div>
                    <p>Uploaded the Example02_AnalogRead.ino code to the RedBoard Artemis Nano. As I read the Serial Monitor, I realized that the temperature was not in units that I could easily understand, so I commented out the two Serial.print commands the original code had. I added my own Serial.print for the variable temp_f which contains the calculated temperature value in Farenheit.</p>
                    <br>
                    
                    <h3>Task 4: Microphone</h3>
                    <div class="video-container">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/_eJQqSUI0n8?si=qZg4RaN_W5M99w2E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </div>
                    <p>Uploaded the Example1_MicrophoneOutput.ino to the RedBoard Artemis Nano and experimented with different pitches to observe the loudest frequency displayed.  </p>
                    <br>

                    <h3>Task 5: Blink with C-note</h3>
                    <div class="video-container">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/W2kiBlS4Hjk?si=SheHTA2CsTtCsFDl" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </div>
                    <p>I combined the Blink.ino and Example1_MicrophoneOutput.ino sketches into one and uploaded it to the board. Then, I searched online for a site that could play a C-note and found one that played both C3 and C4. I played these notes and observed their threshold frequencies. I decided to program the board for the C3 note and added an if-statement in the loop function of the new sketch to turn on the LED if the loudest frequency was within that threshold.   </p>
                    <br>
                    
                    <a href="index.html#lab1a">Back to Lab 1A on main page</a> <!-- Link back to the section on the main page -->
                </div>
            </section>    

<!-- --------LAB 1B-------- -->
            <section id="lab1b">
                <div class="lab-text">
                    <h1>Lab 1B: Bluetooth</h1>
                    <h3>Objective: <span class="objective-text">To establish communication between my computer and the Artemis board via Bluetooth, which I will later use to send data from the Artemis board to the computer. To also be able to send Python commands from a Jupyter Notebook to the Artemis board while running Arduino.</span></h3>
                    <h3>Pre-Lab: <span class="objective-text"> Since I had the latest version of the Arduino, I proceeded with creating a new virtial environment named “FastRobots_ble”. I then activated the virtual environment so I could start working on Jupyter Lab. </span></h3>
                    <h3>Configurations: <span class="objective-text"> First thing I did was upload the ble_arduino.ino code to the Artemis board and get its MAC Address. With this I updated the artemis_address in connections.yaml. I proceeded with generating a new UUID so that it is unique to my board and I replaced the BLEService UUID in the ble_arduino.ino with this new UUID. I connected the Artemis board with the computer via Bluetooth by uploading this code in Jupyter Lab:</span></h3>
                    <img src="bLE.png" alt="Bluetooth code" class="lab-image">
                    <br>
                    
                    <h3>Task 1: Echo</h3>
                    <p>For this task I analyzed the commands PING and SEND_TWO_INTS in the ble_arduino.ino code. With multiple hours of running and debugging I was able to understand what each of their commands do and make something similar for the ECHO command. This is my ECHO command: </p>
                    <img src="ECHO.png" alt="ECHO command" class="lab-image">
                    <p>And this is the Python side of it and how the computer replied to the ECHO command:</p>
                    <img src="task1_python.png" alt="Python Echo response" class="lab-image">
                    <br>

                    <h3>Task 2: SEND_THREE_FLOATS</h3>
                    <p>I started by looking at the command SENT_TWO_INTS once again. I figured that if they are doing this with integers I could modify it so it takes in floats instead of integers, and that is what I did. I copy pasted the code, changed the class to a float and added an extra one so it is three floats being extracted. This is how the command looks in Arduino: </p>
                    <img src="send three floats.png" alt="Send Three Floats Command" class="lab-image">
                    <p>This is the command that was sent via Python:</p>
                    <img src="floats python.png" alt="Send Three Floats Python" class="lab-image">
                    <p>This is what the Serial Monitor in Arduino printed out:</p>
                    <img src="floats serial monitor.png" alt="Send Three Floats Arduino" class="lab-image">
                    <br>

                    <h3>Task 3: GET_TIME_MILLIS</h3>
                    <p>At first, I searched if there is a function in Arduino that would give you the time in milliseconds. Once I saw there is, I copied the code from the ECHO command and modified it so it would print the value of millis(). I ran into an error uploading the code to the board because I forgot to write a class for the millis function, but I then added double and I was able to upload it. This is my GET_TIME_MILLIS command:  </p>
                    <img src="millis arduino.png" alt="Get time millis Command" class="lab-image">
                    <p>Then, when I was trying to call the command on Python it kept showing an error that said “ AttributeError: GET_TIME_MILLIS”. I had not seen this error before and I could not understand it so I asked AI what the error meant and it said that “the command doesn’t exist in the CMD enum”. I remembered seeing in the folder ble_python a code called “cmd_types.py” that looked similar to what AI showed me. I went to that code and added the GET_TIME_MILLIS to it, following ECHO which is how I wrote it in the ble_arduino.ino code, and this is what the Python side looked like after I got it to work: </p>
                    <img src="millis_python.png" alt="Get time millis Python" class="lab-image">
                    <br>

                    <h3>Task 4: Notification Handler</h3>
                    <p> For this task, I created a notification handler that would receive the string from the board and extract the number. In the function I decided to look for "T:" in the string and extract whatever is after that. I was able to do this with the split function I found in the Python cheatsheet that's in the course website. </p>
                    <img src="notif handler.png" alt="Notification handler" class="lab-image">
                    <br>

                    <h3>Task 5: Time Data Sending Loop </h3>
                    <p>I first pasted the code from GET_TIME_MILLIS and then I added the condition so it only collects data for 5 seconds. I initialized both variables at the top of the code (as unsigned long) and then added this new function to the cmd_types.py code. This is TIME_SEND_LOOP in Arduino: </p>
                    <img src="time_send_loop.png" alt="Time Send Loop" class="lab-image">
                    <p>I ran into a few issues with the Python side and then i wanted to add some kind of index value to each line so I ended up altering my notification_handler function. This is the latest version:</p>
                    <img src="notification_handler.png" alt="Updated Notification Handler" class="lab-image"> 
                    <p>And this is what I called in Python and the output. There were 273 timestamps sent from the Arduino in 5 seconds which is about 54.6 messages per second. </p>
                    <img src="python_output.png" alt="Python Output" class="lab-image">
                    <br>

                    <h3>Task 6: Sending Time Data with Arrays </h3>
                    <p>Before diving into the commands, here are the variables I had to initialize globally.</p>
                    <img src="initialized variables.png" alt="Initialized variables" class="lab-image">
                    <p>Here are the updated TIME_SEND_LOOP and the SEND_TIME_DATA. I added a break to the TIME_SEND_LOOP because when I ran it initially it was on a forever printing loop.</p>
                    <img src="new commands.png" alt="New commands" class="lab-image">
                    <p>And this is the Python side:</p>
                    <img src="python interface.png" alt="Python" class="lab-image">
                    <br>

                    <h3>Task 7: Sending Time and Temperature with Arrays </h3>
                    <p>I combined my two commands from before (TIME_SEND_LOOP and SEND_TIME_DATA) and then added the getTempDegF function we used in Lab 1A. When printing I ran into isuees with the time going back after increasing so I joined my while and if statements. I also added a few delays throughout the code so the sensor can have some time to think. </p>
                    <img src="get temp readings.png" alt="Python" class="lab-image">
                    <p>This is the Python side with the output:</p>
                    <img src="get temp readings python.png" alt="Python" class="lab-image">
                    <br>

                    <h3>Task 8: Advantages and Disadvantages of Both Methods </h3>
                    <p>The second method (get_temp_readings) contains the most information which is beneficial because you won't need to run more than one code at a time. However, because it has the most information it takes longer than the first method to run. So if what you are looking is for both sets of data simultaneously then this is the right method. If you only care for the timestamps then the other code might interest you more. The second method has a 70 ms delay in the loop under 5 seconds which means that the system can record about 71 (5000 ms/70 ms) datapoints . Approximately the amount of data you can send without running out of memory would be: (384kB)*(1024 bytes/kB) = 393,216 [bytes of memory available]. And then the temperature reading and timestamp are each 4 bytes, so (393,216/8) = 49,152 entries of time and temperature data could be collected without running out of memory. </p>
                    <br>

<!--                     <h3>Task 9:  </h3>
                    
                    <br>

                    
                    <h3>Task 10:  </h3>
                    
                    <br> -->

                    
                    <h3>Discussion:</h3>
                    <p>In each task, I discussed the challenges I encountered as they arose. Overall, I gained a much deeper understanding of Python’s structure and formatting. While I have had equal experience with Arduino and MATLAB, I was less proficient in Python. However, this lab provided an in-depth exploration of various Python concepts, significantly enhancing my proficiency. For Lab 1 I did look over Nila's page from last year, I double checked my functions whenever an error would pop up. However, I only code what I understand, so there are many things different between her code and mine since it can be seen that her level of profficiency in Python is way higher. Other than that, I used the Python Cheatsheet found in the class website for a few built i funcitons.</p>
                    <br>

                <a href="index.html#lab1b">Back to Lab 1B on main page</a> <!-- Link back to the section on the main page -->
            </section>



<!-- --------LAB 2-------- -->
            
            <section id="lab2">
                <div class="lab-text">
                    <h1>Lab 2: IMU</h1>
                    <h3>Objective: <span class="objective-text">Familiarize myself with the IMU and how to integrate it to your robot. Also play around with the robot given, understand how to use it and its limits and faults. </span></h3>
                    <h3>Pre-Lab: <span class="objective-text">Read up on the IMU and its datasheet. Skim through the lab instructions as well, so that when I get to the lab, I can start immediately since it's extensive.</span></h3>
                    <br>
                    
                    <h3>TASK 1: SET UP THE IMU </h3>
                    <p>I already had the libraries needed in Arduino because we used them in class so I proceeded to connect my IMU to the Artemis board via the QWICC connectors.</p>
                    <img src="artemis_imu.jpg" alt="IMU" class="lab-image">
                    <p>I then ran the example code Example1_Basics from the SparkFun 9DOF IMU Breakout ICM-20948 Arduino Library. This is what it outputted:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/ddwSwPX0hdY?si=39NRvYvRptkVME6h" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <br>
                    <h3>AD0 Value Discussion: </h3>
                    <p>The AD0_VAL represents the value of the last bit in the I2C address. The default on the IMU is 1, but when the ADR jumper is closed, the value becomes 0. This controls the I2C address of the IMU: when AD0_VAL is 1, the address is 0x69, and when AD0_VAL is 0, the address is 0x68. This is useful when using multiple IMUs on the same I2C bus, allowing them to have different addresses and communicate independently.</p>
                    <br>
                    <h3>Acc. & Gyr. Discussion:</h3>
                    <p>To observe changes in accelerometer and magnetometer values, I placed the IMU in three different orientations and analyzed the serial monitor output. When positioned right-side up on a horizontal surface, the accelerometer readings were around 20 mg in the X and Y directions, indicating minimal tilt. In the Z direction, the values were around 1000 mg (~1g), meaning gravity was the primary acceleration detected. The gyroscope readings in this position were approximately 0 DPS, aside from minor offsets, which is expected since the IMU was stationary and should not register rotational movement. Here is the IMU in the upright orientation:</p>
                    <img src="example_code.jpg" alt="example code" class="lab-image">
                    <br>

                    <h3>TASK 2:ACCELEROMETER </h3>
                    <p>For this part, I adapted the code from Example1_Basics, edited the loop funciton and made a new function. At first my values for pitch and roll were printing out like if they were switched, but after talking with the Professor we realized that the lecture notes had a typo and the equations for roll and pitch were switched. We fixed it and got it working accordingly. These are my edits to the previous code:</p>
                    <pre><code>
void loop(){

  if (myICM.dataReady()) { 
                        
    myICM.getAGMT(); 
    getRollandPitch(myICM.accX(),myICM.accY(),myICM.accZ());
    delay(50); }
  else {
    SERIAL_PORT.println("Waiting for data");
    delay(500);}}



void getRollandPitch(float x,float y,float z) {
  float roll = 0;
  float pitch = 0;

  roll = atan2(y,z)*180/M_PI; 
  pitch = atan2(x,z)*180/M_PI; 

  SERIAL_PORT.print("Roll:");
  SERIAL_PORT.print(roll);
  SERIAL_PORT.print(" | Pitch:");
  SERIAL_PORT.println(pitch);}
                    </code></pre>
                    
                    <p>And this is the output at {-90,0,90}:</p>
                    <img src="pitch_roll.jpg" alt="pitch and roll" class="lab-image">
                    <br>
                    <p>Accelerometer accuracy dicussion:  For this part I decided to take bits of a sketch I had from a past project, adapt all the top stuff from the previous example code and then print out the conversion factor of each axis after collecting raw data. This is what the code printed:</p>
                    <pre><code>
Conv. Factor X: 0.41
Conv. Factor Y: 0.00
Conv. Factor Z: -0.00
                    </code></pre>
                    <p>From this data we can see that the y and z axis' values are fairly calibrated already, but the x does have an offset. Note: I did not collect data to calibrate the X-axis in this code. It only collected data from the IMU facing up and facing down (aka the Z-axis).</p>
                    <br>

                    <h3>Noise in the frequency spectrum analysis: </h3>
                    <p>The accelerometer is highly sensitive to its environment, which is why it tends to exhibit noise even when lying flat on my desk. To ensure accurate data collection when using the robot, this noise should be analyzed in the frequency spectrum. To achieve this, I recorded accelerometer data on the Artemis and transferred it to my computer to graph both the raw noise and its Fourier transform. This is the code I used in Python for the Fourier transform:  </p>
                    <img src="FT.png" alt="FT" class="lab-image">
                    <p>With this I graphed the raw noise for roll and pitch and their respective Fourier transform plot. </p>
                    <table>
                        <tr>
                            <td><img src="raw_rollNoise.png" alt="Raw roll noise" width="300"></td>
                            <td><img src="raw_rollFT.png" alt="Raw roll FT" width="300"></td>
                        </tr>
                    </table>
                    <table>
                        <tr>
                            <td><img src="raw_pitchNoise.png" alt="Raw pitch noise" width="300"></td>
                            <td><img src="raw_pitchFT.png" alt="Raw pitch FT" width="300"></td>
                        </tr>
                    </table>
                    
                    <p>I then introduced vibrational noise by hitting the desk three times while the IMU was flat on it and you can observe the additional noise in the raw data plots.   </p>
                    <table>
                        <tr>
                            <td><img src="vib_rawRoll.png" alt="Vib raw roll" width="300"></td>
                            <td><img src="vib_rollFT.png" alt="Vib roll FT" width="300"></td>
                        </tr>
                    </table>
                    <table>
                        <tr>
                            <td><img src="vib_rawPitch.png" alt="Vib raw pitch" width="300"></td>
                            <td><img src="vib_pitchFT.png" alt="Viv pitch FT" width="300"></td>
                        </tr>
                    </table>
                    <p>Based off these plots, I chose </p>
                    
                    
                <a href="index.html#lab2">Back to Lab 2 on main page</a> 
            </section>
            
<!-- --------LAB 3-------- -->
            <section id="lab3">
                <div class="lab-text">
                    <h1>Lab 3: ToF</h1>
<!--                     <h2>Objective: <span class="objective-text">To enhance the robot's capabilities by integrating distance sensors. The quicker my robot can take measurements and the more reliable my sensor readings are, the faster it can operate. </span></h2> -->
                    <h2>PRE-LAB</h2>
                    <h3>NOTE THE I2C ADDRESS: <span class="objective-text">The default I2C address of the time of flight sensor according to the data sheet is 0x52.</span></h3>
                    <br>
                    <h3>TWO ToF SENSORS APPROACH: <span class="objective-text">I intend to incorporate two ToF sensors on my robot to enhance the accuracy of obstacle detection. By using multiple sensors, I can average the measurements obtained from both devices, which will help mitigate any discrepancies in individual readings. The improved accuracy in measuring distances will significantly reduce the likelihood of collisions and potential damage to the robot, ensuring smoother operation and enhanced safety during its tasks.</span></h3>
                    <br>
                    <h3>PLACEMENT OF SENSORS: <span class="objective-text">By positioning both ToF sensors at the front corners of the robot, I am maximizing the coverage area in the front which helps identify objects that may approach from the sides, such as a wall jutting out into its path. If both sensors were placed in the middle or one in the middle and one in the back, the robot might miss detecting these side obstacles, potentially leading to collisions. However, this corner placement may not detect certain obstacles directly in front of the robot if they are positioned too close, as the sensors might not have the required angle to accurately measure the distance. Furthermore, since the sensors are only located at the front, any obstacles that appear from behind the robot will go undetected, leaving the robot vulnerable to unexpected challenges.</span></h3>
                    <br>
                    <h3>SKETCH OF WIRING DIAGRAM: <span class="objective-text">For my ToF sensors, I decided to programmatically change the address of the second distance sensor when it is powered on so I wired the XSHUT pin of one of the sensors to the A8 pin on the Artemis board. </span></h3>
                    <img src="wiring sketch.png" alt="Wiring sketch diagram" class="lab-image">
                    <br>

                    <h2>TASKS</h2>
                    <h3>TASK 1: TOF SENSOR CONNECTION TO QWICC BREAKOUT BOARD</h3>
                    <img src="ToF_connections.jpg" alt="ToF connections" class="lab-image">
                    <br>

                    <h3>TASK 2: ARTEMIS SCANNING THE I2C DEVICE</h3>
                    <p>In the data sheet, the default address for the time of flight sensor is listed as 0x52. However, the serial monitor output shows it as 0x29. This discrepancy arises because the data sheet presents the address in an 8-bit format, while Arduino utilizes a 7-bit address. The conversion from 0x52 to 0x29 occurs by shifting the 8-bit address one bit to the right: 0x52 >> 1 = 0x29. This removes the write bit (0).</p>
                    <img src="I2C scanning.png" alt="I2C scanning" class="lab-image">
                    <br>

                    <h3>TASK 3: SENSOR DATA WITH CHOSEN MODE</h3>
                    <p>The ToF sensor supports three distance modes: Short, Medium, and Long. Short mode provides the highest resistance to ambient lighting interference, making it the most reliable option in well-lit environments. However, it has the shortest range, reaching up to 1.3 meters. Medium mode extends the sensor’s range to 3 meters. Long mode allows the sensor to detect objects up to 4 meters away, but it is the most sensitive to ambient lighting, making it more prone to inaccuracies in bright environments. Since I am prioritizing accuracy over range in my data collection, I have chosen to use Short mode for my final robot.</p>
                    <p>Here is a picture of the setup for data collection:</p>
                    <img src="sensorMode_setup.jpg" alt="Sensor mode setup" class="lab-image">

                    <p>I made a new command in Arduino to collect the data from the ToF sensor :</p>
                    <img src="ToFcommand.png" alt="ToF command" class="lab-image">

                    <p>And this is the Python side:</p>
                    <img src="tof_python1.png" alt="ToF python part 1" class="lab-image">
                    <img src="tof_python2.png" alt="ToF python part 2" class="lab-image">
                    
                    <p>To measure the range of my ToF I recorded measurements in evenly spaced distances between 0.25m and 1.75m from my computer to a stand. It can be seen in the graph below that discrepancies between the measured and actual distances become more noticeable beyond 1.3m. </p>
                    <img src="SensorRangePlot.png" alt="Sensor range plot" class="lab-image">
                    
                    <p>To evaluate accuracy, I plotted the difference between the measured and actual distances against the actual distances. It is important to note that some human error may be present, as the placement of the sensor may not have been perfectly precise. However, after the 1.3m threshold the difference starts being larger. </p>
                    <img src="AccuracyPlot.png" alt="Accuracy plot" class="lab-image">
                    
                    <p>In the standard deviation versus actual distance plot seen below, the standard deviation remains between 2.5–5 mm until it approaches the 1.3 m threshold, where it begins to increase. </p>
                    <img src="RepeatabilityPlot.png" alt="Repeatability plot" class="lab-image">

                    <p>To analyze the ranging time, I recorded a time array while collecting distance measurements on the Arduino side and then passed it to the Python side. Using this data, I calculated the mean ranging time for each set of collected distance measurements which can be seen below. </p>
                    <img src="Ranging time.png" alt="Ranging time" class="lab-image">
                    <br>

                    <h3>TASK 4: TWO TOF SENSORS AND IMU WORKING IN PARALLEL</h3>
                    <p>To integrate and collect data of the second ToF sensor I changed the address of my second distance sensor and set its XSHUT pin to high so it would program it in the sensor. For this I added the section shown below into my GET_TOF command in Arduino (full code shown in previous task): </p>
                    <img src="2TOFcommand.png" alt="Command for two ToF" class="lab-image">
                    <p>For the rest of the code of distance sensor 2 I just duplicated the commands that were used for distance sensor 1. This is the output of both distance sensors in the Serial Monitor:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/khzG77BJ_Wc?si=huXHCQxHLSMwT4Ov" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <p>This is the output when integrating the IMU data:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/MnZ7R2TSkcE?si=5MLgL07DmZD1kQup" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    
                    <h3>TASK 5: TOF SENSOR SPEED</h3>
                    <p>To measure how fast my loop executes I collected the time before and after going into my loop that checks whether both sensors' data is ready. The loop is right before collecting the data and storing the values in an array (full code seen previously). The limiting factor in this case is waiting until both sensors are ready to start collecting data. This is the code snippet in my GET_TOF command:  </p>
                    <img src="TOFspeedSnippet.png" alt="Command for two ToF" class="lab-image">
                    <p>And this is the output in the Serial Monitor:</p>
                    <img src="TOFspeed.png" alt="Command for two ToF" class="lab-image">
                    
                    <h3>TASK 6: TIME V DISTANCE</h3>
                    <p>For this, I placed a box in front of my ToF sensors and moved the entire setup (IMU and ToF sensors) back and forth relative to the box while simultaneously moving the IMU up and down. One of the ToF sensors was slightly farther back than the other which is why there is a slight offset between them. This is the ToF sensors' plot: </p>
                    <img src="Distance vs Time.png" alt="Distance vs time" class="lab-image">
                    
                    <h3>TASK 7: TIME V ANGLE</h3>
                    <p>These are the plots for the accelerometer and gyroscope data with the same movement as before:</p>
                    <table>
                        <tr>
                            <td><img src="AnglevsTime_accel.png" alt="Angle vs time accelerometer" width="300"></td>
                            <td><img src="AnglevsTime_gyro.png" alt="Angle vs time gyroscope" width="300"></td>
                        </tr>
                    </table>

                    <h3>5000 LEVEL - DISCUSSION: INFRARED TRANSMISSION BASED SENSORS</h3>
                    <p> Two common types of distance sensors are LiDAR sensors and infrared (IR) proximity sensors. According to the <a href="https://youtu.be/2Y9zFh_CpAU?si=gS6qSH3VusWtcxeK" target="_blank">"Distance Sensor Comparison Guide"</a> video by SparkFun Electronics on YouTube, a LiDAR sensor works by emitting continuous pulses of laser light and measuring the time it takes for the beam to return to the sensor. In contrast, an IR proximity sensor determines distance by measuring the intensity of the reflected infrared beam.LiDAR sensors are ideal for long-range measurements, but they have high power consumption and are more expensive compared to other distance sensors. On the other hand, IR proximity sensors offer moderate range and resolution at a lower cost, but they are highly sensitive to ambient light and surface colors, which can affect their accuracy.</p>

                    <h3>5000 LEVEL: SENSITIVITY OF SENSORS TO COLORS AND TEXTURES</h3>
                    <p>I observed the measurements of each distance sensor for a blanket texture and the colors red, blue and yellow. For all cases, the values remained within the same range, aside from slight variations due to minor changes in sensor positioning from human error. This is the setup:</p>
                    <table>
                        <tr>
                            <td><img src="setup1.jpg" alt="set up 1" width="300"></td>
                            <td><img src="setup2.jpg" alt="set up 2" width="300"></td>
                        </tr>
                    </table>
                    <p>I then just proceeded to change the color in the screen for each set of data. The data collected for each color is shown below:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/xy6uDSWwkf8?si=0l5m9ZBf-V_qMLZe" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/31cJ1cZn32w?si=HYdnhtgx_FdvKXuZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/t2pg2YYiEmE?si=RkdgWTFQWYgjf17p" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/cKaAQZ_bUoM?si=mNFQQitUxIrBWdAn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<!--                     <br> -->
                    
                    <h3>REFERENCES:</h3>
                    <p>For this Lab I referenced the past lab reports of Mikayla Lahr and Patty Meza.</p>
                    
                <a href="index.html#lab3">Back to Lab 3 on main page</a> 
            </section>
            
    <!-- --------LAB 4-------- -->
            <section id="lab4">
                <div class="lab-text">
                    <h1>Lab 4: Motor Drivers and Open Loop Control</h1>
                    <h2>PRE-LAB</h2>
                    <h3>WIRING DIAGRAM: <span class="objective-text"> I started by reviewing the lecture notes and then taking a look at what Nila Narayan and Mikayla Lahr did last year. I then came up with this wiring diagram where AIN1 and BIN1 are connected in series to pin 0 and 4, for motor drivers 1 and 2 respectively. AIN2 and BIN2 follow the same setup but in pins 1 and 5, for motor drivers 1 and 2 respectively. And then, AOUT1 with BOUT1 and AOUT2 with BOUT2 are connected in series with eachother and then solder to each positive and negative lead of the DC motor, respectively.</span></h3>
                    <img src="motorDriverwires.jpg" alt="Motor drivers' wiring" class="lab-image">
                    <br>
                    <h3>BATTERY DISCUSSION: <span class="objective-text">The Artemis board and the motors are powered separately to keep everything running smoothly. Motors can cause sudden changes in current, which might mess with the Artemis and make it glitch or reset. Using separate batteries prevents those power spikes from interfering with the board. Plus, motors need more power, so giving them their own battery makes sure they get enough without affecting the Artemis.</span></h3>
                    <br>

                    <h2>TASKS</h2>
                    <h3>PWM TESTS:</h3>
                    <p>Before soldering the motor drivers to the motors themselves, I connected every OUT pin individually to the oscilloscope to make sure it is reading and ooutputting corrrectly. To do this, I connected the VIN and GND pins of the motor driver to the power supply and sent an output of around 3.7V which is a reasonable input voltage withing their 10V range. Below you can see my setup with a motor driver connected to the oscilloscope and power supply.  </p>
                    <img src="IMG_7260.jpg" alt="Power supply setup" class="lab-image">
                    <p> This is the code I burned on the Artemis to see if I can regulate the power on the motor driver output.</p>
                    <img src="analogCode.png" alt="Analog code for oscilloscope" class="lab-image">
                    <p>Here is an image of the output of the oscilloscope (each OUT pin), this plot remained constant when sending a 200 PWM signal to each OUT pin.</p>
                    <img src="IMG_7256.jpg" alt="Power supply setup" class="lab-image">
                    
                    <h3>TESTING INDIVIDUAL MOTORS:</h3>
                    <p>I proceeded to wire the motors and upload code to the Artemis board that will run one set of the wheels forward and then the same one backwards. The other set of wheels' code was commented out when working on this part. This is the code: </p>
                    <img src="eachSet_turns.png" alt="Each wheel set turns" class="lab-image">
                    <p>This is how the robot reacted:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/ybmaBvgfM-c?si=L4XBTq2sPk4HABGf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/-5GV7pHTpVw?si=HC6hKRZ0vKLp8eci" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

                    <h3>FULLY BATTERY POWERED MOTOR DRIVERS:</h3>
                    <p>Here I then moved from the power supply to the 850mAh battery given to us. And after some soldering, I was able to connect all the wires and upload this code:</p>
                    <img src="allWheels_turn.png" alt="All wheels turn" class="lab-image">
                    <p>In which the wheels moved as so:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/RevvYjTSwGw?si=40AmAM1Pn_3-7dXc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    
                    <h3>CAR CHASSIS SETUP:</h3>
                    <img src="robot_components.jpeg" alt="Robot components" class="lab-image">

                    <h3>LOWER LIMIT PWM:</h3>
                    <p>For the task where we tested the motor drivers running entirely on battery power, I wrote a simple code to make the car move forward for a few seconds and then backward. Since I was testing the motors, I decided to lower the PWM values—not only to observe their effects but also because I had limited space to run the car. I first reduced the PWM value to 100, then to 50, and finally to 45 to see if the car could move even slower. From these tests, I observed that at a PWM of 50, the car could complete its commands, but after a while, it started getting stuck as friction overpowered the movement. At 45, the car couldn't start at all, suggesting that this value is close to the minimum PWM required for the car to move. </p>
                    
                    <h3>CALIBRATION:</h3>
                    <p>Before showing my calibrated code, let's take a look at how my robot performed when commanded to drive straight for 3 seconds at 60 PWM, so it reaches 6ft (the end of the blue tape is 6ft):</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/qPRmzwZZ9xA?si=2PZAgihux8f_qxcO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    
                    <p>As you can see, my right wheels are moving faster than my left wheels. To calibrate this, I made an estimated guess for an initial value, starting at 1.2 and increasing it by 0.2 until I reached 1.8, where the robot was able to move in a straight line for 6 feet</p>
                    <p>While running these calibration tests, I noticed that the robot would sometimes move forward in small pulses. I found this strange, so I checked the wiring and discovered that the lead of one of the motor driver's soldered GND wires wasn't cut down properly and was touching the Vin wire. After fixing this issue, the car worked as expected.</p>
                    <p>This is how the car performed after including the calibration factor into the code: </p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/bQ-fnFbHAkY?si=51lPf-r2BKMt4oxn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <p>The loop function was getting long so I started making functions for each command and this is the code the car ran:</p>
                    <img src="straightLineCode1.png" alt="Straight Line calibrated code1" class="lab-image">
                    <img src="straightLineCode2.png" alt="Straight Line calibrated code2" class="lab-image">

                    <h3>ADDING TURNS:</h3>
                    <p>For this part, I added a simple turn function to my code. Since the pins for moving forward are 0 and 5, and the pins for moving backward are 1 and 4, the pins for turning would be 0 and 4 for a left turn and 5 and 1 for a right turn.</p>
                    <img src="turn function.png" alt="Turn function" class="lab-image">
                    <img src="turn addition loop.png" alt="Turn function" class="lab-image">
                    <p>And this is how the robot performed with a turn:</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/-YFFgVuFQaU?si=0Qafong4edcvi5XP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


                    <h2>REFERENCES</h2>
                    <p>For this Lab I referenced the past lab reports of Mikayla Lahr, Nila Narayan and Patty Meza. I used ChatGPT to fix my grammar and spelling. Also went to office hours during the weekend and the late session on Monday night, very much appreciated. </p>
                    
                <a href="index.html#lab4">Back to Lab 4 on main page</a> 
            </section>

            
  <!-- --------LAB 5-------- -->
            <section id="lab5">
                <div class="lab-text">
                    <h1>Lab 5: Linear PID and Linear Interpolation</h1>
                    <h2>PRE-LAB</h2>
                    <h3>BLUETOOTH: <span class="objective-text"> In the Pre-lab, I developed a method to send and receive PID data via Bluetooth, allowing for data collection and debugging. To implement this, I created a flag in Arduino that I constantly check its state in my main loop to act accordingly and several new commands: </span></h3>
                    <ul>
                        <li><strong>START_PID:</strong> Clears all previously stored data, starts ToF sensor ranging and clock and sets the <code>PID_live</code> flag to <code>true</code> (initialized as <code>false</code> at the start of the sketch).</li>
                        <li><strong>STOP_PID:</strong> Resets the <code>PID_live</code> flag to <code>false</code> and stops the motors.</li>
                        <li><strong>SET_PID_GAINS:</strong> Receives input values from Python and updates the PID gain constants globally in Arduino.</li>
                        <li><strong>SEND_PID:</strong> Transmits the collected PID data to the computer via Bluetooth.</li>
                    </ul>
                    <pre><code>
case START_PID:
{
    // only start if not already on
    if (PID_live) return;
                        
    distance_array1.clear; 
    motor_speedArray.clear;
    time_pid.clear;

    int pid_idx = 0; //index used in the loop
    int time_pid_start = millis();
    TOFSensor1.startRanging();
    PID_live = true;
                        
    break;
}
        
case STOP_PID:
{
    // only stop running if still on
    if (!PID_live) return;

    PID_live = false;
    stop_motors();

    break;
}

case SET_PID_GAINS:
{
    success = robot_cmd.get_next_value(Kp);
    if (!success)
        return;

    success = robot_cmd.get_next_value(Ki);
    if (!success)
        return;

    success = robot_cmd.get_next_value(Kd);
    if (!success)
        return;

    K_p = Kp;
    K_i = Ki;
    K_d = Kd;

    break;
}
        
case SEND_PID:
{
    for (int i = 0; i < ArraySize; i++) {
        tx_estring_value.clear();
        tx_estring_value.append(time_pid[i]);
        tx_estring_value.append(",");
        tx_estring_value.append(distance_array1[i]);
        tx_estring_value.append(",");
        tx_estring_value.append(motor_speedArray[i]);
        tx_characteristic_string.writeValue(tx_estring_value.c_str());
    }
    break;
}
                    </code></pre>
                    <br>
                    
                    <h2>TASKS</h2>
                    <h3>POSITION CONTROL:</h3>
<!--                     <img src="IMG_7260.jpg" alt="Power supply setup" class="lab-image"> -->
                    
                <a href="index.html#lab5">Back to Lab 5 on main page</a> 
            </section>

            
 <!-- --------LAB 6-------- -->
            <section id="lab6">
                <h2>Lab 6: Orientation PID</h2>
                <p>Details about Lab 6...</p>
                <a href="index.html#lab6">Back to Lab 6 on main page</a> 
            </section>

            
 <!-- --------LAB 7-------- -->
            <section id="lab7">
                <h2>Lab 7: Kalman Filtering</h2>
                <p>Details about Lab 7...</p>
                <a href="index.html#lab7">Back to Lab 7 on main page</a> 
            </section>

            
 <!-- --------LAB 8-------- -->
            <section id="lab8">
                <h2>Lab 8: Stunts!</h2>
                <p>Details about Lab 8...</p>
                <a href="index.html#lab8">Back to Lab 8 on main page</a> 
            </section>

            
 <!-- --------LAB 9-------- -->
            <section id="lab9">
                <h2>Lab 9: Mapping</h2>
                <p>Details about Lab 9...</p>
                <a href="index.html#lab9">Back to Lab 9 on main page</a> 
            </section>

            
 <!-- --------LAB 10-------- -->
            <section id="lab10">
                <h2>Lab 10: Localization (sim)</h2>
                <p>Details about Lab 10...</p>
                <a href="index.html#lab10">Back to Lab 10 on main page</a> 
            </section>

            
 <!-- --------LAB 11-------- -->
            <section id="lab11">
                <h2>Lab 11: Localization (real)</h2>
                <p>Details about Lab 11...</p>
                <a href="index.html#lab11">Back to Lab 11 on main page</a> 
            </section>

            
 <!-- --------LAB 12-------- -->
            <section id="lab12">
                <h2>Lab 12: Planning and Execution</h2>
                <p>Details about Lab 12...</p>
                <a href="index.html#lab12">Back to Lab 12 on main page</a> 
            </section>
        </div>
    </section>

<button id="backToTop">↑ Back to Top</button>
    
    <!-- Footer -->
<!--     <footer>
        <p>&copy; 2025 Aleira Sanchez. All rights reserved.</p>
    </footer> -->
</body>
</html>
