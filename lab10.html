<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aleira N. Sanchez - Labs</title>
    <link rel="stylesheet" href="style.css">
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
</head>
<body>
    <!-- Navigation Bar -->
    <nav>
        <a href="index.html" class="logo">Aleira N. Sanchez</a>
        <ul>
            <!-- Other sections -->
            <li class="dropdown">
                <span class="bold-text">Labs</span>
                <div class="dropdown-content">
                    <a href="lab1.html">Lab 1: Artemis and Bluetooth</a>
                    <a href="lab2.html">Lab 2: IMU</a>
                    <a href="lab3.html">Lab 3: ToF</a>
                    <a href="lab4.html">Lab 4: Motor Drivers and Open Loop Control</a>
                    <a href="lab5.html">Lab 5: Linear PID and Linear Interpolation</a>
                    <a href="lab6.html">Lab 6: Orientation PID</a>
                    <a href="lab7.html">Lab 7: Kalman Filtering</a>
                    <a href="lab8.html">Lab 8: Stunts!</a>
                    <a href="lab9.html">Lab 9: Mapping</a>
                    <!-- Add more labs as needed -->
                </div>
            </li>
        </ul>
    </nav>

    <button class="home-button" onclick="goHome()">Return to Home</button>

    <script>
        function goHome() {
            window.location.href = "index.html"; // Adjust if your homepage is in a different folder
        }
    </script>

    
    <!-- Labs Details Section -->
    <section id="labs-subpage">
        <div class="gallery">
            <section id="lab10">
                <div class="lab-text">
                    <h1>Lab 10: Localization(sim)</h1>
                    <h2>PRE-LAB: </h2>
                    <p>I followed the instructions provided in the Simulation tool—installing all dependencies, the appropriate wheel file for my OS and Python version, and the Box2D library. Using the GUI, I explored various commands to observe how the robot would respond. I used Open Loop Control to navigate the robot through the space and observed that movement commands continued indefinitely unless explicitly counteracted by an opposing command. Below is a plot comparing the robot’s odometry with the ground truth for the trajectory I created.</p>
                    <img src="prelab10.png" alt="Prelab lab 10" class="lab-image">
                    <p>Analyzing the odometry plot (the red dots) it does not look accurate at all. However, the ground truth plot (green dots) seem accurate with just a few undershooting angles in a few turns.</p>
                    <h2>TASKS: </h2>
                    <p>The following function were written to run the Bayes Filter.</p>
                    
                    <h3>COMPUTE CONTROL:</h3>
                    <p>The compute_control() function calculates the first rotation, translation, and second rotation by using the robot’s current pose and previous pose as inputs. The equations used for these calculations are shown below (from Lecture 18). </p>
                    <img src="computeControlEqns.png" alt="Eqxns compute control" class="lab-image">
                    <p>To simplify the equations in Pyhton, I created a variable called x_component to store the difference between the x-coordinates of the current and previous poses. I did the same for the y-coordinates.</p>
                    <img src="computeControl.png" alt="Compute control" class="lab-image">
                  
                    <h3>ODOMETRY MOTION MODEL: </h3>
                    <p>The odom_motion_model() function also takes in the current pose and previous pose, but it additionally considers the odometry control input. It uses the parameters calculated by the compute_control() function and estimates the probability that the robot reached its current position given the previous pose. These probabilities are modeled using a Gaussian distribution.</p>
                    <img src="odomMotionModel.png" alt="Odom Motion Model" class="lab-image">
                    
                    <h3>PREDICTION STEP:</h3>
                    <p>The prediction_step() function calculates the probability that the robot is in each cell of the grid. It does this by taking the current and previous poses and iterating through the entire grid to compute a predicted belief using the odom_motion_model() function.</p>
                    <p> To reduce computational load, the function skips calculations for cells where the probability drops below 0.0001, since the likelihood of the robot being in those cells is very low. While this speeds up the process, it can slightly reduce the precision and accuracy of the filter.</p>
                    <img src="predictionStep.png" alt="Prediction step" class="lab-image">
                    
                    <h3>SENSOR MODEL:</h3>
                    <p>The sensor_model() function calculates the probability of each input observation occurring in the current state, modeling them with a Gaussian distribution. It returns a 1D array of the same size as the input, where each element represents the corresponding probability.</p>
                    <img src="sensorModel.png" alt="Sensor model" class="lab-image">
                    
                    <h3>UPDATE STEP:</h3>
                    <p>And finally, the update_step() function iterates through all the cells in the grid, gets the probability at each cell using sensor_model(), and then updates the belief by multiplying this probability with the predicted belief. The resulting values are then normalized.</p>
                    <img src="updateStep.png" alt="Update step" class="lab-image">
                    
                    <h3>SIMULATION RESULTS:</h3>
                    <p>Here is my succesful run of the Bayes Filter simulation. It ran for 15 iterations, which can be seen below.</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/MAcdy25hTOM?si=F6G0CSGgJD5TLQ8v" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    <p>And this is the final plot for this run:</p>
                    <img src="run2_plot.png" alt="Run 2 plot" class="lab-image">
                    <p>The red line represents the odometry measurements, the green line is the ground truth, and the blue line shows the belief. The different shades of grid cells indicate the strength of the belief—lighter cells represent higher belief values. </p>
                    <p>You can see how the ground truth and belief follow very similar paths, which is good. The probability however seems to be pretty noisy and not precise. Which I may need to consider when uploading the Bayes filter rto my robot for the next lab. </p>
                    <p>Overall, I think the Bayes filter would perform reasonably well on the robot, but it may require a second set of data to validate the results, as the filter appears to be a bit noisy.</p>
                    
                    <h3>REFERENCES:</h3>
                    <p>For this lab I referenced, Stephan Wagner's and Mikayla Lahr's labs from previous years. I also used ChatGPT to help with the grammar.</p>
            </section>
        </div>
    </section>
</body>
</html>
